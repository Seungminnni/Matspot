import asyncio
import re
from typing import List, Optional

import aiosqlite
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware

# --- 1. Pydantic ëª¨ë¸ ì •ì˜ ë° FastAPI ì•± ì„¤ì • ---
class Place(BaseModel):
    id: str; place_name: str; category_name: str; phone: Optional[str] = None; address_name: str
    road_address_name: Optional[str] = ""; x: str; y: str; place_url: str; distance: Optional[str] = None

class SearchRequest(BaseModel):
    searchResults: List[Place]
    rankingPreference: str = 'balanced' 

class RankedPlace(Place):
    review_count: int; instagram_mentions: int; score: float

app = FastAPI()

# --- CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€ ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins, allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

INSTA_DB_PATH = "finally.db"
REVIEW_DB_PATH = "restarant.db"

# --- 2. DB ì¡°íšŒ í•¨ìˆ˜ë“¤ (ìµœì¢… ì•ˆì •í™” ë²„ì „) ---
async def fetch_review_counts_from_db(places: List[Place]) -> dict:
    """ë¦¬ë·° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¦¬ë·° ìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. (ê°œì„ ëœ ë§¤ì¹­ ì „ëµ)"""
    print(f"ğŸ” ë¦¬ë·° DB ì¡°íšŒ ì‹œì‘ (ì¥ì†Œ ê°œìˆ˜: {len(places)})")
    review_map = {}
    if not places: return review_map
    
    TABLE_NAME, NAME_COL, ADDRESS_COL, REVIEW_COL = "mapinformation", "name", "address2", "reviewnum"
    
    def normalize_place_name(name):
        """ì¥ì†Œëª…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤"""
        # ë‹¤ì–‘í•œ ë³€í˜• ì²˜ë¦¬
        normalized = name
        normalized = normalized.replace("ì˜ëŒ€ì ", "ì˜ë‚¨ëŒ€ì ")
        normalized = normalized.replace("ê²½ì‚°ì˜ëŒ€", "ê²½ì‚°ì˜ë‚¨ëŒ€")
        normalized = normalized.replace("ì˜ë‚¨ëŒ€í•™êµ", "ì˜ë‚¨ëŒ€")
        return normalized
    
    def extract_core_name(name):
        """í•µì‹¬ ë§¤ì¥ëª…ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì§€ì ëª… ì œê±°)"""
        # ì§€ì ëª… íŒ¨í„´ë“¤ ì œê±°
        core = re.sub(r'\s*(ì˜ëŒ€ì |ì˜ë‚¨ëŒ€ì |ê²½ì‚°ì |ë³¸ì |ì‹ ëŒ€ì )\s*$', '', name)
        core = re.sub(r'\s*ê²½ì‚°\s*', '', core)  # ê²½ì‚° ì œê±°
        return core.strip()
    
    def extract_address_keywords(address):
        """ì£¼ì†Œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤"""
        if not address:
            return []
        # ì£¼ìš” ë„ë¡œëª…, ê±´ë¬¼ëª… ë“± ì¶”ì¶œ
        keywords = []
        # ë„ë¡œëª… ì¶”ì¶œ (ì˜ˆ: "ì²­ìš´ë¡œ", "ëŒ€í•™ë¡œ59ê¸¸")
        road_pattern = r'([ê°€-í£]+(?:ë¡œ|ê¸¸)\d*[ê°€-í£]*)'
        roads = re.findall(road_pattern, address)
        keywords.extend(roads)
        
        # ê±´ë¬¼ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "12-6", "280")
        number_pattern = r'(\d+(?:-\d+)?)'
        numbers = re.findall(number_pattern, address)
        keywords.extend(numbers)
        
        return keywords
    
    try:
        async with aiosqlite.connect(REVIEW_DB_PATH) as db:
            for place in places:
                cleaned_address = place.road_address_name
                if cleaned_address: 
                    cleaned_address = re.sub(r'\s+[A-Za-z0-9ê°€-í£]+ì¸µ$', '', cleaned_address).strip()
                
                original_name = place.place_name
                print(f"  ğŸ“‹ ê²€ìƒ‰: '{original_name}' + '{cleaned_address}'")
                
                # ì „ëµ 1: ì›ë³¸ ì´ë¦„ + ì£¼ì†Œë¡œ ê²€ìƒ‰
                query = f"SELECT {REVIEW_COL} FROM {TABLE_NAME} WHERE {NAME_COL} LIKE ? AND {ADDRESS_COL} LIKE ? LIMIT 1"
                params = (f"%{original_name}%", f"%{cleaned_address}%")
                cursor = await db.execute(query, params)
                result = await cursor.fetchone()
                
                # ì „ëµ 2: ì •ê·œí™”ëœ ì´ë¦„ + ì£¼ì†Œë¡œ ê²€ìƒ‰
                if not result:
                    normalized_name = normalize_place_name(original_name)
                    if normalized_name != original_name:
                        print(f"    ğŸ”„ ì •ê·œí™”ëœ ì´ë¦„: '{normalized_name}'")
                        params = (f"%{normalized_name}%", f"%{cleaned_address}%")
                        cursor = await db.execute(query, params)
                        result = await cursor.fetchone()
                
                # ì „ëµ 3: í•µì‹¬ ì´ë¦„ë§Œ + ì£¼ì†Œ í‚¤ì›Œë“œ ë§¤ì¹­
                if not result:
                    core_name = extract_core_name(original_name)
                    address_keywords = extract_address_keywords(cleaned_address)
                    
                    if core_name and address_keywords:
                        print(f"    ğŸ”„ í•µì‹¬ ë§¤ì¹­: '{core_name}' + ì£¼ì†Œí‚¤ì›Œë“œ {address_keywords}")
                        
                        # ì£¼ì†Œ í‚¤ì›Œë“œ ì¤‘ ê°€ì¥ êµ¬ì²´ì ì¸ ê²ƒìœ¼ë¡œ ë§¤ì¹­
                        for keyword in address_keywords:
                            if len(keyword) >= 2:  # ë„ˆë¬´ ì§§ì€ í‚¤ì›Œë“œëŠ” ì œì™¸
                                query = f"SELECT {REVIEW_COL} FROM {TABLE_NAME} WHERE {NAME_COL} LIKE ? AND {ADDRESS_COL} LIKE ? LIMIT 1"
                                params = (f"%{core_name}%", f"%{keyword}%")
                                cursor = await db.execute(query, params)
                                result = await cursor.fetchone()
                                if result:
                                    print(f"      âœ… í‚¤ì›Œë“œ '{keyword}'ë¡œ ë§¤ì¹­ë¨")
                                    break
                
                # ì „ëµ 4: ì£¼ì†Œ ê¸°ì¤€ ìš°ì„  ë§¤ì¹­ (ì´ë¦„ì€ ë¶€ë¶„ ë§¤ì¹­)
                if not result and cleaned_address:
                    address_keywords = extract_address_keywords(cleaned_address)
                    core_name = extract_core_name(original_name)
                    
                    # ê°€ì¥ ê¸´ ì£¼ì†Œ í‚¤ì›Œë“œë¡œ ë¨¼ì € ë§¤ì¹­ ì‹œë„
                    if address_keywords:
                        main_keyword = max(address_keywords, key=len)
                        if len(main_keyword) >= 3:
                            print(f"    ğŸ”„ ì£¼ì†Œ ìš°ì„  ë§¤ì¹­: ì£¼ì†Œ '{main_keyword}' + ì´ë¦„ ë¶€ë¶„ë§¤ì¹­")
                            
                            # ì£¼ì†Œê°€ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ê³³ì—ì„œ ì´ë¦„ ìœ ì‚¬ë„ ê²€ì‚¬
                            query = f"SELECT {NAME_COL}, {REVIEW_COL} FROM {TABLE_NAME} WHERE {ADDRESS_COL} LIKE ? AND {NAME_COL} LIKE ?"
                            params = (f"%{main_keyword}%", f"%{core_name[:3]}%")  # ì´ë¦„ ì• 3ê¸€ìë¡œ í•„í„°ë§
                            cursor = await db.execute(query, params)
                            candidates = await cursor.fetchall()
                            
                            if candidates:
                                # ê°€ì¥ ìœ ì‚¬í•œ ì´ë¦„ ì„ íƒ
                                best_match = None
                                best_score = 0
                                
                                for candidate_name, review_count in candidates:
                                    # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ê³µí†µ ê¸€ì ìˆ˜ / ì „ì²´ ê¸€ì ìˆ˜)
                                    common_chars = len(set(core_name) & set(candidate_name))
                                    similarity = common_chars / max(len(core_name), len(candidate_name))
                                    
                                    if similarity > best_score:
                                        best_score = similarity
                                        best_match = (candidate_name, review_count)
                                
                                if best_match and best_score > 0.3:  # 30% ì´ìƒ ìœ ì‚¬í•˜ë©´ ë§¤ì¹­
                                    result = (best_match[1],)
                                    print(f"      âœ… ì£¼ì†Œë§¤ì¹­ '{best_match[0]}' (ìœ ì‚¬ë„: {best_score:.2f})")
                
                # ê²°ê³¼ ì²˜ë¦¬
                if result and result[0] is not None:
                    try:
                        review_count = int(result[0]) if str(result[0]).isdigit() else 0
                        review_map[place.id] = review_count
                        print(f"    âœ… ìµœì¢… ë§¤ì¹­: {review_count}ê°œ ë¦¬ë·°")
                    except (ValueError, TypeError) as e:
                        print(f"    âŒ ë¦¬ë·°ìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {result[0]} (ì˜¤ë¥˜: {e})")
                        review_map[place.id] = 0
                else:
                    print(f"    âŒ ëª¨ë“  ì „ëµ ì‹¤íŒ¨")
                    
        print(f"ğŸ” ë¦¬ë·° DB ì¡°íšŒ ì™„ë£Œ. {len(review_map)}ê°œ ì¥ì†Œ ë§¤ì¹­ë¨.")
        return review_map
        
    except Exception as e: 
        print(f"âŒ ë¦¬ë·° DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}

async def fetch_insta_mentions_from_db(places: List[Place]) -> dict:
    """[ê°œì„ ] ì¸ìŠ¤íƒ€ê·¸ë¨ ì–¸ê¸‰ ìˆ˜ë¥¼ ë” ì •í™•í•˜ê²Œ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤."""
    print(f"ğŸ“¸ ì¸ìŠ¤íƒ€ DB ì¡°íšŒ ì‹œì‘ (ì¥ì†Œ ê°œìˆ˜: {len(places)})")
    mention_map = {p.id: 0 for p in places}
    if not places: return mention_map
    
    TABLE_NAME = "instagram_posts"
    CAPTION_COL = "caption_text"
    HASHTAG_COL = "hashtags_representation"

    def normalize_place_name(name):
        """ì¥ì†Œëª…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤ (ë¦¬ë·° DBì™€ ë™ì¼í•œ ë¡œì§)"""
        normalized = name
        normalized = normalized.replace("ì˜ëŒ€ì ", "ì˜ë‚¨ëŒ€ì ")
        normalized = normalized.replace("ê²½ì‚°ì˜ëŒ€", "ê²½ì‚°ì˜ë‚¨ëŒ€")
        normalized = normalized.replace("ì˜ë‚¨ëŒ€í•™êµ", "ì˜ë‚¨ëŒ€")
        return normalized
    
    def extract_core_name(name):
        """í•µì‹¬ ë§¤ì¥ëª…ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì§€ì ëª… ì œê±°)"""
        core = re.sub(r'\s*(ì˜ëŒ€ì |ì˜ë‚¨ëŒ€ì |ê²½ì‚°ì |ë³¸ì |ì‹ ëŒ€ì )\s*$', '', name)
        core = re.sub(r'\s*ê²½ì‚°\s*', '', core)
        return core.strip()

    try:
        async with aiosqlite.connect(INSTA_DB_PATH) as db:
            for place in places:
                main_name = place.place_name.split()[0]
                unique_keywords = set()
                
                # ì´ë¦„ ê¸¸ì´ì— ë”°ë¥¸ ê²€ìƒ‰ ì „ëµ
                if len(main_name) < 2:
                    print(f"  ğŸ“‹ '{place.place_name}' - í•œ ê¸€ì ì´ë¦„, ì£¼ì†Œë¡œ ê²€ìƒ‰")
                    cleaned_address = place.road_address_name
                    if cleaned_address:
                        cleaned_address = re.sub(r'\s+[A-Za-z0-9ê°€-í£]+ì¸µ$', '', cleaned_address).strip()
                        if cleaned_address: 
                            unique_keywords.add(cleaned_address)
                else:
                    print(f"  ğŸ“‹ '{place.place_name}' - ë‘ ê¸€ì ì´ìƒ, ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰")
                    
                    # ì›ë³¸ ì´ë¦„ë“¤ ì¶”ê°€
                    original_name = place.place_name
                    unique_keywords.add(original_name)
                    unique_keywords.add(original_name.replace(" ", ""))
                    unique_keywords.add(main_name)
                    
                    # ì •ê·œí™”ëœ ì´ë¦„ë“¤ ì¶”ê°€ (ì˜ëŒ€ì  -> ì˜ë‚¨ëŒ€ì  ë“±)
                    normalized_name = normalize_place_name(original_name)
                    if normalized_name != original_name:
                        print(f"    ğŸ”„ ì •ê·œí™”ëœ ì´ë¦„ ì¶”ê°€: '{normalized_name}'")
                        unique_keywords.add(normalized_name)
                        unique_keywords.add(normalized_name.replace(" ", ""))
                    
                    # í•µì‹¬ ì´ë¦„ ì¶”ê°€ (ì§€ì ëª… ì œê±°)
                    core_name = extract_core_name(original_name)
                    if core_name and core_name != original_name:
                        print(f"    ğŸ”„ í•µì‹¬ ì´ë¦„ ì¶”ê°€: '{core_name}'")
                        unique_keywords.add(core_name)
                
                unique_keywords = {kw for kw in unique_keywords if kw and len(kw) >= 2}
                print(f"    ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {unique_keywords}")

                if not unique_keywords:
                    print(f"    âŒ ê²€ìƒ‰ í‚¤ì›Œë“œ ì—†ìŒ")
                    continue

                # ê° í‚¤ì›Œë“œë³„ë¡œ ê°œë³„ ê²€ìƒ‰í•˜ì—¬ ì´í•© ê³„ì‚° (ì¤‘ë³µ ì œê±°)
                total_mentions = 0
                found_posts = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í¬ìŠ¤íŠ¸ ID ì €ì¥
                
                for keyword in unique_keywords:
                    # ìº¡ì…˜ì—ì„œ ê²€ìƒ‰
                    caption_query = f"SELECT id FROM {TABLE_NAME} WHERE {CAPTION_COL} LIKE ?"
                    cursor = await db.execute(caption_query, (f"%{keyword}%",))
                    caption_posts = await cursor.fetchall()
                    caption_count = len(caption_posts)
                    
                    # í•´ì‹œíƒœê·¸ì—ì„œ ê²€ìƒ‰ (ì´ë¦„ì¸ ê²½ìš°ë§Œ)
                    hashtag_count = 0
                    hashtag_posts = []
                    if len(main_name) >= 2:
                        hashtag_query = f"SELECT id FROM {TABLE_NAME} WHERE {HASHTAG_COL} LIKE ?"
                        cursor = await db.execute(hashtag_query, (f"%#{keyword}%",))
                        hashtag_posts = await cursor.fetchall()
                        hashtag_count = len(hashtag_posts)
                    
                    # ì¤‘ë³µ ì œê±°í•˜ì—¬ í¬ìŠ¤íŠ¸ ID ì¶”ê°€
                    for post in caption_posts:
                        found_posts.add(post[0])
                    for post in hashtag_posts:
                        found_posts.add(post[0])
                    
                    keyword_total = caption_count + hashtag_count
                    print(f"      '{keyword}': ìº¡ì…˜ {caption_count} + í•´ì‹œíƒœê·¸ {hashtag_count} = {keyword_total}")

                # ì¤‘ë³µ ì œê±°ëœ ì´ ì–¸ê¸‰ ìˆ˜
                total_mentions = len(found_posts)
                mention_map[place.id] = total_mentions
                print(f"    âœ… ì´ ì–¸ê¸‰ ìˆ˜ (ì¤‘ë³µì œê±°): {total_mentions}")

        matched_count = sum(1 for v in mention_map.values() if v > 0)
        print(f"ğŸ“¸ ì¸ìŠ¤íƒ€ DB ì¡°íšŒ ì™„ë£Œ. {matched_count}ê°œ ì¥ì†Œ ë§¤ì¹­ë¨.")
        return mention_map
        
    except Exception as e: 
        print(f"âŒ ì¸ìŠ¤íƒ€ DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {p.id: 0 for p in places}

# --- 3. API ì—”ë“œí¬ì¸íŠ¸ ë° í•µì‹¬ ë¡œì§ (ì´ì „ê³¼ ë™ì¼) ---
@app.post("/api/restaurants/process-search", response_model=List[RankedPlace])
async def process_and_rank_restaurants(request: SearchRequest):
    search_results = request.searchResults
    ranking_preference = request.rankingPreference
    if not search_results: return []

    WEIGHT_PRESETS = {
        'distance':  {'distance': 0.45, 'reviews': 0.3, 'mentions': 0.25},
        'reviews':   {'distance': 0.2, 'reviews': 0.8, 'mentions': 0.0},
        'instagram': {'distance': 0.2, 'reviews': 0.0, 'mentions': 0.8},
        'balanced':  {'distance': 0.25, 'reviews': 0.375, 'mentions': 0.375}
    }
    weights = WEIGHT_PRESETS.get(ranking_preference, WEIGHT_PRESETS['balanced'])
    print(f"\n--- ê°€ì¤‘ì¹˜ í”„ë¦¬ì…‹ '{ranking_preference}'(ìœ¼)ë¡œ ë­í‚¹ì„ ê³„ì‚°í•©ë‹ˆë‹¤. (ê°€ì¤‘ì¹˜: {weights}) ---")

    try:
        review_map, insta_map = await asyncio.gather(
            fetch_review_counts_from_db(search_results), 
            fetch_insta_mentions_from_db(search_results)        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB ì¡°íšŒ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    enriched_places = []
    print("\nğŸ“Š ë°ì´í„° í†µí•© ì‹œì‘:")
    for place in search_results:
        enriched_data = place.model_dump()
        review_count = review_map.get(place.id, 0)
        insta_mentions = insta_map.get(place.id, 0)
        
        enriched_data['review_count'] = review_count
        enriched_data['instagram_mentions'] = insta_mentions
        enriched_data['distance'] = int(place.distance) if place.distance and place.distance.isdigit() else 99999
        
        print(f"  ğŸª {place.place_name}: ë¦¬ë·° {review_count}, ì¸ìŠ¤íƒ€ {insta_mentions}, ê±°ë¦¬ {enriched_data['distance']}m")
        enriched_places.append(enriched_data)
    
    if not enriched_places: return []
    max_dist = max(p['distance'] for p in enriched_places) or 1
    max_revs = max(p['review_count'] for p in enriched_places) or 1
    max_ment = max(p['instagram_mentions'] for p in enriched_places) or 1
    
    scored_places = []
    for p in enriched_places:
        norm_revs = (p['review_count'] / max_revs) if max_revs > 0 else 0
        norm_ment = (p['instagram_mentions'] / max_ment) if max_ment > 0 else 0
        norm_dist = (1 - (p['distance'] / max_dist)) if max_dist > 0 else 0
        score = norm_dist * weights['distance'] + norm_revs * weights['reviews'] + norm_ment * weights['mentions']
        p['distance'] = str(p['distance'])
        scored_places.append(RankedPlace(**p, score=score))
    
    ranked_list = sorted(scored_places, key=lambda p: p.score, reverse=True)
    return ranked_list[:45]

# í”„ë¡ íŠ¸ì—”ë“œ ìš”ì²­ì„ ìœ„í•œ /recommend ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
class RecommendRequest(BaseModel):
    places: List[Place]
    ranking_preference: str = 'instagram'

class RecommendResponse(BaseModel):
    recommended_places: List[RankedPlace]

@app.post("/recommend", response_model=RecommendResponse)
async def recommend_places(request: RecommendRequest):
    """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    # ê¸°ì¡´ SearchRequest í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    search_request = SearchRequest(
        searchResults=request.places,
        rankingPreference=request.ranking_preference
    )
    
    # ê¸°ì¡´ ì¶”ì²œ ë¡œì§ ì¬ì‚¬ìš©
    recommended_places = await process_and_rank_restaurants(search_request)
    
    return RecommendResponse(recommended_places=recommended_places)

# =======================================================
#  â˜… ì„œë²„ ì‹¤í–‰ ë¸”ë¡ â˜…
# =======================================================
if __name__ == "__main__":
    import uvicorn
    print("FastAPI ì¶”ì²œ ë°±ì—”ë“œ ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("API ë¬¸ì„œ: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)